{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prerequisites on libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Library import\n",
    "import os, sys\n",
    "import datetime\n",
    "\n",
    "## Libraries for basic data-processing & visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "!pip install -U seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "## Libraries for decision-tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from IPython.display import Image\n",
    "import graphviz\n",
    "from sklearn.externals.six import StringIO\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:\\Program Files (x86)\\Graphviz2.38/bin/' # for adding to PATH\n",
    "try:\n",
    "    import pydotplus\n",
    "except:\n",
    "    !pip install pydotplus\n",
    "    import pydotplus\n",
    "    \n",
    "## Libraries for logistic-regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "## Library for evaluation on classification\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "## Libraries for Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "\n",
    "## Random seed for reproductivity, especially for Keras\n",
    "from numpy.random import seed\n",
    "seed(0)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(0)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import timeit\n",
    "\n",
    "## import opencv for python\n",
    "try:\n",
    "    import cv2\n",
    "except:\n",
    "    !pip install opencv-python\n",
    "    import cv2\n",
    "\n",
    "from scipy import ndimage\n",
    "try:\n",
    "    from joblib import Parallel, delayed\n",
    "except:\n",
    "    !pip install joblib\n",
    "    from joblib import Parallel, delayed    \n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WKDIR = '../data/'\n",
    "os.chdir(WKDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load data & its definition\n",
    "\n",
    "In this chapter, we load raw data from csv-format data. Original data is [this site](https://www.kaggle.com/johndddddd/customer-satisfaction).\n",
    "\n",
    "Also, we review the basic functions on pandas & numpy in comparing SQL syntax. Please note in advance that they don't cover all functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data import\n",
    "SATISFACTION_FILE = 'satisfaction.csv'\n",
    "df = pd.read_csv(SATISFACTION_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Size of DataFrame (row numbers, column numbers)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confirm data columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of each column\n",
    "\n",
    "\n",
    "|Column|Description|Data examples|\n",
    "|-----|:-----:|:-----|\n",
    "|satisfaction_v2|Airline satisfaction level|Satisfaction, neutral or dissatisfaction|\n",
    "|Gender|Gender of the passengers |Female, Male|\n",
    "|Customer Type|The customer type|Loyal customer, disloyal customer|\n",
    "|Age|The actual age of the passengers||\n",
    "|Type of Travel|Purpose of the flight of the passengers|Personal Travel, Business Travel|\n",
    "|Class|Travel class in the plane of the passengers|Business, Eco, Eco Plus|\n",
    "|Flight Distance|The flight distance of this journey||\n",
    "|Seat comfort|Satisfaction level of Seat comfort||\n",
    "|Departure/Arrival time convenient|Satisfaction level of Departure/Arrival time convenient||\n",
    "|Food and drink|Satisfaction level of Food and drink||\n",
    "|Gate location|Satisfaction level of Gate location||\n",
    "|Inflight wifi service|Satisfaction level of the inflight wifi service|0:Not Applicable;1-5|\n",
    "|Inflight entertainment|Satisfaction level of inflight entertainment||\n",
    "|Online support|??||\n",
    "|Ease of Online booking|Satisfaction level of online booking||\n",
    "|On-board service|Satisfaction level of On-board service||\n",
    "|Leg room service|Satisfaction level of Leg room service||\n",
    "|Baggage handling|Satisfaction level of baggage handling||\n",
    "|Checkin service|Satisfaction level of Check-in service||\n",
    "|Cleanliness|Satisfaction level of Cleanliness||\n",
    "|Online boarding|Satisfaction level of online boarding||\n",
    "|Departure Delay in Minutes|Minutes delayed when departure||\n",
    "|Arrival Delay in Minutes|Minutes delayed when Arrival|\n",
    "\n",
    "\n",
    "\n",
    "Ref. https://www.kaggle.com/johndddddd/customer-satisfaction/home"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.1 Projection\n",
    "\n",
    "If SQL, ...\n",
    "```SQL\n",
    "SELECT\n",
    "    TOP(10) [Flight Distance]\n",
    "FROM\n",
    "    TABLE_SATISFACTION\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Flight Distance'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.2 Projection with plural columns\n",
    "If SQL, ...\n",
    "```SQL\n",
    "SELECT\n",
    "    TOP(5) [Flight Distance], [Type of Travel]\n",
    "FROM\n",
    "    TABLE_SATISFACTION\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Flight Distance', 'Type of Travel']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.3 Select distinct\n",
    "\n",
    "If SQL, ...\n",
    "\n",
    "```SQL\n",
    "SELECT\n",
    "    DISTINCT [Flight Distance]\n",
    "FROM\n",
    "    TABLE_SATISFACTION\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Flight Distance'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.4 filter\n",
    "\n",
    "If SQL, ...\n",
    "\n",
    "```SQL\n",
    "SELECT\n",
    "    TOP(10) *\n",
    "FROM\n",
    "    TABLE_SATISFACTION\n",
    "WHERE\n",
    "    Gender = 'Female'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"Gender == 'Female'\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.5 order by\n",
    "\n",
    "If SQL, ...\n",
    "```SQL\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    TABLE_SATISFACTION\n",
    "ORDER BY\n",
    "    [Flight Distance]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('Flight Distance').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.6 group by & aggregate function\n",
    "\n",
    "If SQL, ...\n",
    "```SQL\n",
    "SELECT\n",
    "    AVG([Flight Distance])\n",
    "    ,[Type of Travel]\n",
    "FROM\n",
    "    TABLE_SATISFACTION\n",
    "GROUP BY\n",
    "    [Type of Travel]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Flight Distance', 'Type of Travel']].groupby('Type of Travel').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.7 Case statement\n",
    "\n",
    "If SQL, ...\n",
    "```SQL\n",
    "SELECT\n",
    "    CASE [satisfaction_v2]\n",
    "        WHEN 'satisfied' THEN 1\n",
    "        ELSE 0\n",
    "    END AS [target]\n",
    "FROM\n",
    "    TABLE_SATISFACTION\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = df['satisfaction_v2'].apply(lambda x: 1 if x == 'satisfied' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.8 group by & count\n",
    "\n",
    "If SQL, ...\n",
    "```SQL\n",
    "SELECT\n",
    "    COUNT(1)\n",
    "    ,[Type of Travel]\n",
    "FROM\n",
    "    TABLE_SATISFACTION\n",
    "GROUP BY\n",
    "    [Type of Travel]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Type of Travel'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.9 Populate dummy variables\n",
    "\n",
    "If SQL, ...\n",
    "```SQL\n",
    "SELECT\n",
    "    CASE [Type of Travel]\n",
    "        WHEN 'Business trave' THEN 1\n",
    "        ELSE 0\n",
    "    END AS [Business trave]\n",
    "    ,CASE [Type of Travel]\n",
    "        WHEN 'Personal Travel' THEN 1\n",
    "        ELSE 0\n",
    "    END AS [Personal Travel]\n",
    "FROM\n",
    "    TABLE_SATISFACTION\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df['Type of Travel']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.10 pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(df, values=['Flight Distance', 'Seat comfort', 'Online boarding'], index='Type of Travel', aggfunc='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Slice on dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract first 10 rows\n",
    "## Attention!! index of python starts from 0.\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract 15th row to 20th row\n",
    "df[15:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use iloc, If we focus on specific columns\n",
    "df.iloc[15:20, [4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Or, slice after projection by pandas\n",
    "df['Age'][15:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The above 2 objects are different, though...\n",
    "print(type(df.iloc[15:20, [4]]))\n",
    "print(type(df['Age'][15:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Basic summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Basic statistics for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Check 'NA'(Not Applicable) value for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().apply(lambda col: col.value_counts(), axis=0).fillna(0).astype(np.int).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Viaualize & understand data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Check distribution on single colum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize Flight distance\n",
    "sns.distplot(df['Flight Distance'], kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To-Do: Put another column name on argument of the dataframe \n",
    "col_single = 'Food and drink'\n",
    "sns.distplot(df[col_single], kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Understand relation of several columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate correlational coefficient\n",
    "np.corrcoef(df['Seat comfort'], df['Food and drink'])[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To-Do: ut other columns on argument of calculating\n",
    "col1_corr = 'Inflight wifi service'\n",
    "col2_corr = 'Inflight entertainment'\n",
    "\n",
    "np.corrcoef(df[col1_corr], df[col2_corr])[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correlation matrix for some variables\n",
    "\n",
    "col_corr = ['Flight Distance'\n",
    "            ,'Seat comfort'\n",
    "            ,'Food and drink'\n",
    "            ,'Inflight wifi service'\n",
    "            ,'Inflight entertainment'\n",
    "            ,'Online support'\n",
    "            ,'Cleanliness'\n",
    "            ,'Ease of Online booking'\n",
    "            ,'Departure Delay in Minutes']\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "sns.heatmap(df[col_corr].corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Scatter plot on 2 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try to depict scatter plot, ...\n",
    "sns.scatterplot(df['Food and drink'], df['Leg room service']) ## variant is too small ..:("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## with density for each observation\n",
    "sns.jointplot(df['Food and drink'], df['Leg room service'], kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate correlational coefficient\n",
    "np.corrcoef(df['Food and drink'], df['Leg room service'])[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depict_corr_matrix(col1, col2):\n",
    "    ## Calculate & print correlation coefficient\n",
    "    corr = np.corrcoef(df[col1], df[col2])[1,0]\n",
    "    print('Correlational coefficient is {}'.format(corr))\n",
    "    ## Depict joint plot\n",
    "    sns.jointplot(df[col1], df[col2], kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## In summary, ...\n",
    "depict_corr_matrix('Food and drink', 'Leg room service')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try another combination\n",
    "depict_corr_matrix('Inflight wifi service', 'Inflight entertainment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try another combination\n",
    "depict_corr_matrix('Food and drink', 'Seat comfort')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Machine Learning\n",
    "\n",
    "In this chapter, we consider statistical model, which predict passengers' satisfaction with other variables.\n",
    "\n",
    "- Goal of this chapter\n",
    "  - Select some given variables and confirm which variable impacts the satisfaction as a whole.\n",
    "    - Decision Tree Classifier\n",
    "    - Logistic Classifier\n",
    "\n",
    "- Notes:\n",
    "  - In order to move forward, we put `target` as target variable: 1: `satisfied`, 0: `neutral or dissatisfied`\n",
    "  - In next chapter, we pursuit the predictivity with deep-learning technique and compare the accuracy with logistic classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Decision Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_ml= ['Flight Distance'\n",
    "        ,'Seat comfort'\n",
    "        ,'Food and drink'\n",
    "        ,'Inflight wifi service'\n",
    "        ,'Inflight entertainment'\n",
    "        ,'Online support'\n",
    "        ,'Ease of Online booking'\n",
    "        ,'Departure Delay in Minutes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define decision tree model\n",
    "clf = DecisionTreeClassifier(random_state=0, max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the whole data into train & test\n",
    "Obs_for_train = 120000\n",
    "X_train = df[col_ml][:Obs_for_train]\n",
    "y_train = df['target'][:Obs_for_train]\n",
    "X_test = df[col_ml][Obs_for_train:]\n",
    "y_test = df['target'][Obs_for_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optimize parameters of the model\n",
    "dt = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate accuracy\n",
    "accuracy_dt = dt.score(X_test, y_test)\n",
    "print(accuracy_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check feature importance for eadh variable\n",
    "dt.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.barplot(col_ml, dt.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## F1 score\n",
    "f1_score(y_test, dt.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Depict tree\n",
    "dot_data = StringIO()\n",
    "tree.export_graphviz(dt \n",
    "                     ,out_file=dot_data\n",
    "                     ,feature_names=col_ml\n",
    "                     ,filled=True\n",
    "                     ,rounded=True\n",
    "                     ,special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url= \"https://www.cntk.ai/jup/logistic_neuron.jpg\", width=300, height=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define logistic regression\n",
    "clf_log = LogisticRegression(random_state=0, solver='lbfgs', max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate accuracies\n",
    "accuracy_lr = clf_log.score(X_test, y_test)\n",
    "print(accuracy_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Each partial regression coefficient\n",
    "clf_log.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare partial regression coefficients\n",
    "sns.set()\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.barplot(col_ml, clf_log.coef_[0])\n",
    "plt.title('Partial regression coefficient on logistic regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confusiton matrix\n",
    "confusion_matrix(y_test, clf_log.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## F1 score\n",
    "f1_score(y_test, clf_log.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Deep Learning\n",
    "\n",
    "- In this chapter, we'd like to pursuit predictive accuracy with deep-learning technique, especially MLP(=Multi-Layer Perceptron). Please treat this content as introduction for deep-learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Equivalent to logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(1, input_dim=X_train.shape[1], activation='sigmoid'))\n",
    "\n",
    "model1.compile(loss='binary_crossentropy'\n",
    "             ,optimizer='adam'\n",
    "             ,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = model1.fit(X_train, y_train, epochs=100, batch_size=1001, verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history1.history['loss'], label='train')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch number')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1, accuracy_dl1 = model1.evaluate(X_test, y_test)\n",
    "print('loss: {}, accuracy: {}'.format(loss1, accuracy_dl1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 MLP -- Adding layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(5, input_dim=X_train.shape[1], activation='relu'))\n",
    "model2.add(Dense(5, activation='relu'))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "model2.compile(loss='binary_crossentropy'\n",
    "             ,optimizer='adam'\n",
    "             ,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model2.fit(X_train, y_train, epochs=100, batch_size=1000, verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history2.history['loss'], label='train')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch number')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss2, accuracy_dl2 = model2.evaluate(X_test, y_test)\n",
    "print('loss: {}, accuracy: {}'.format(loss2, accuracy_dl2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Compare accuracies for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ['Decision Tree', 'Logistic regression', 'equivalent to Log-reg', 'MLP']\n",
    "sns.set()\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.barplot(model_name, [accuracy_dt, accuracy_lr, accuracy_dl1, accuracy_dl2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Tips on execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Save used memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confirm current data sets\n",
    "sys.getsizeof(X_train) # 7680104 bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert sparse format\n",
    "X_train_sparse = pd.get_dummies(X_train).to_sparse(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confirm converted data sets\n",
    "sys.getsizeof(X_train_sparse) # 7028848 bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ck_accuracy(X_train, y_train, X_test, y_test):\n",
    "    ## Optimize parameters of the model\n",
    "    dt = clf.fit(X_train, y_train)\n",
    "\n",
    "    ## Calculate accuracy\n",
    "    accuracy_dt = dt.score(X_test, y_test)\n",
    "    print(accuracy_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Original data sets\n",
    "ck_accuracy(X_train, y_train, X_test, y_test)\n",
    "\n",
    "## Converted data sets\n",
    "ck_accuracy(X_train_sparse, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Check process time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define sample function\n",
    "def test(n):\n",
    "    sum(range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Primitive method - difference between snart & end\n",
    "\n",
    "n=1000000\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "test(n)\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "process_time = end_time - start_time\n",
    "\n",
    "print('Total process time is {}'.format(process_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit  #Magic function for iPython Notebook(=Jupyter Notebook)\n",
    "test(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Parallel process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Definition of rotation\n",
    "rIntr = 30\n",
    "## Start angle\n",
    "rs = 30\n",
    "## Final angle\n",
    "re = 330\n",
    "\n",
    "## input images\n",
    "Image_DIR = '../data/'\n",
    "## output images\n",
    "output_DIR = '../data/output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFilesInDirectory(directory, postfix = \"\"):\n",
    "    fileNames = [s for s in os.listdir(directory) if not os.path.isdir(os.path.join(directory, s))]\n",
    "    if not postfix:\n",
    "        return fileNames\n",
    "    else:\n",
    "        return [s for s in fileNames if s.lower().endswith(postfix)]\n",
    "\n",
    "## mirror inversion\n",
    "def generate_flip(I):\n",
    "    fimg = I.copy()\n",
    "    return cv2.flip(fimg ,0)   \n",
    "\n",
    "## Generate(rotate) images & store for each image\n",
    "def generate_rot(imgFilename, rs, re, rIntr, output_DIR, image_type):\n",
    "    I = cv2.imread(imgFilename)\n",
    "    ## mirror-inversion, if needed\n",
    "    if image_type == 'Reverse':       \n",
    "        I = generate_flip(I)\n",
    "    for r in range(rs, re+1, rIntr):\n",
    "        ## Rotation of each image\n",
    "        Irot = ndimage.rotate(I, r, reshape=False)\n",
    "        ## Store images\n",
    "        format_r = '{0:03d}'.format(r)\n",
    "        FILENAME = imgFilename+'_'+str(image_type)+'_'+str(format_r)+'.jpg'\n",
    "        print('Completed for '+str(FILENAME))\n",
    "        cv2.imwrite(os.path.join(output_DIR,FILENAME), Irot)\n",
    "\n",
    "## Present all images in a folder\n",
    "def show_images(imgFilenames, path, image_Num=10):\n",
    "    for ind, img in enumerate(imgFilenames):\n",
    "        if ind <= image_Num:\n",
    "            print(img)\n",
    "            image = cv2.imread(path+img)\n",
    "            decoded_bytes = cv2.imencode('.jpg', image)[1].tobytes()\n",
    "            display(Image(data=decoded_bytes, width=300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get file names of Input images\n",
    "os.chdir(Image_DIR)\n",
    "imgFilenames = getFilesInDirectory(Image_DIR, \".jpg\")\n",
    "\n",
    "## Make directory for output\n",
    "try:\n",
    "    os.mkdir(output_DIR)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confirm the imported images\n",
    "show_images(imgFilenames, Image_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check time lapse in rotating images with single processing\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "for imgFilename in imgFilenames:\n",
    "    generate_rot(imgFilename=imgFilename, \n",
    "                                    rs=rs, \n",
    "                                    re=re, \n",
    "                                    rIntr=rIntr, \n",
    "                                    output_DIR=output_DIR, \n",
    "                                    image_type='Normal')\n",
    "\n",
    "process_time = datetime.datetime.now() - start\n",
    "print('Process time with single process: {}'.format(process_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check time lapse in rotating images with parallel processing\n",
    "start = datetime.datetime.now()\n",
    "Parallel(n_jobs=-1, verbose=3,\n",
    "    backend=\"threading\"\n",
    "    )([delayed(generate_rot)(imgFilename=imgFilename, \n",
    "                                    rs=rs, \n",
    "                                    re=re, \n",
    "                                    rIntr=rIntr, \n",
    "                                    output_DIR=output_DIR,\n",
    "                                    image_type='Normal') \n",
    "#                                    image_type='Reverse') ## if mirror inversion\n",
    "                                   for imgFilename in imgFilenames])\n",
    "process_time = datetime.datetime.now() - start\n",
    "print('Process time with parallel process: {}'.format(process_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confirm the generated images\n",
    "out_imgFilenames = getFilesInDirectory(output_DIR, \".jpg\")\n",
    "show_images(out_imgFilenames, output_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. References\n",
    "\n",
    "- pandas: https://pandas.pydata.org/\n",
    "- seaborn: https://seaborn.pydata.org/\n",
    "- scikit-learn\n",
    "    - decision-tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "    - logistic regression: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "    - metrics for classification: http://scikit-learn.org/stable/modules/classes.html#classification-metrics\n",
    "- keras: https://keras.io/\n",
    "- Magic function in iPython Notebook: https://ipython.readthedocs.io/en/stable/interactive/tutorial.html#magic-functions\n",
    "- joblib: https://pypi.org/project/joblib/\n",
    "- cv2(opencv for python): https://pypi.org/project/opencv-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
